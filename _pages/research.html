---
permalink: /research
title: "Research | Trustworthy AI Lab | Simon Fraser University"
barename: research
redirect_from:
  - /research.html
---

<div class="row" style="margin-top:50px; margin-bottom:25px">
  <div class="col d-flex justify-content-center">
    <div class="card" style="max-width: 800px;">
      <div class="card-header card-title mission-card-title">
        <h5>Our Mission</h5>
        <p class="text-muted">
          Promote fully <b>Trustworthy and Aligned Artificial General Intelligence</b>, with a focus on certifiability, through theroetically principled approaches.
        </p>
      </div>
      <img src="/assets/imgs/lab_research_overview.svg" class="card-img-top" alt="lab_overview">
      <div class="card-body">
        <div class="row">
          <div class="col-6">
            <ul>
              <li><b>Principled Understanding</b>: We aim to understand how different capabilities are correlated and jointly acquired and stored in large deep learning models. This enables us to systematically analyze why practical trustworthiness threats exist.</li>
            </ul>
          </div>
          <div class="col-6">
            <ul>
              <li><b>Certifiable Mitigations</b>: We aim to fix the trustworthiness threats in large deep learning models certifiably. We develop certification methods for large deep learning models, and combine them with data refinement and model refinement.</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="row">
  <h3>Representative Research</h3>
  <hr>
</div>

  <div class="card">
    <div class="row g-0">
      <div class="col-md-4">
        <img src="/assets/imgs/research_pics/infibench_1.png" class="img-fluid rounded-start" alt="infibench_main">
        <img src="/assets/imgs/research_pics/infibench_2.png" class="img-fluid rounded-start" alt="infibench_scaling_law">
      </div>
      <div class="col-md-8 research-div">
        <div class="card-body">
          <h5 class="card-title">InfiBench: Benchmarking Question-Answering for Code LLMs</h5>
          <div class="card-text" style="min-height: 350px">
            <p>
              <a href="https://infi-coder.github.io/infibench/" target="_blank">[project page]</a>
              &nbsp;
              <a href="https://arxiv.org/abs/2404.07940" target="_blank">[paper]</a>
              &nbsp;
              <a href="https://github.com/infi-coder/infibench-evaluation-harness/" target="_blank">[code]</a>
              &nbsp;
              <a href="/assets/research_slides/infibench_slides.pdf" target="_blank">[slides]</a>
              &nbsp;
              <a href="https://openreview.net/forum?id=E8EAeyTxOy" target="_blank">[OpenReview]</a>
            </p>
            <p>
              <ul>
                <li>A high-quality human-annotated benchmark for code-related question-answering for large language models (LLMs).</li>
                <li>Sourced from StackOverflow. 234 questions. Rule-based model-free evaluation criteria from human experts.</li>
                <li>Over 100 evaluated code LLMs - largest leaderboard for code LLMs to our best knowledge.</li>
                <li>Revealing empirical scaling laws for both code models and generic models and highlighting barriers and challenges.</li>
                <li>Fully open-source.</li>
              </ul>
            </p>
          </div>
        </div>
        <div class="card-footer text-muted">
          NeurIPS 2024 (Datasets and Benchmarks Track)
        </div>
      </div>
    </div>
  </div>

  <div class="card">
    <div class="row g-0 align-items-center">
      <div class="col-md-4">
        <img src="/assets/imgs/research_pics/sok.png" class="img-fluid rounded-start" alt="sok_taxonomy">
      </div>
      <div class="col-md-8 research-div">
        <div class="card-body">
          <h5 class="card-title">SoK: Certified Robustness for Deep Neural Networks</h5>
          <div class="card-text">
            <p>
              <a href="https://sokcertifiedrobustness.github.io/" target="_blank">[project page]</a>
              &nbsp;
              <a href="https://arxiv.org/abs/2009.04131" target="_blank">[paper]</a>
              &nbsp;
              <a href="https://github.com/AI-secure/VeriGauge" target="_blank">[code]</a>
              &nbsp;
              <a href="/assets/research_slides/SP2023-presentation.pdf" target="_blank">[slides]</a>
              &nbsp;
              <a href="https://www.youtube.com/watch?v=hrBeUVRCixI" target="_blank">[talk]</a>
            </p>
            <p>
              <ul>
                <li>A comprehensive systemization of knowledge on DNN (deep neural networks) certified robustness, summarizing latest efforts in this important topic.</li>
                <li>Discussion on practical and theoretical implications, findings, main challenges, and future directions.</li>
                <li>Accompanied with an open-source unified platform to evaluate 20+ representative approaches.</li>
              </ul>
            </p>
          </div>
        </div>
        <div class="card-footer text-muted">
          IEEE S&P (Oakland) 2023
        </div>
      </div>
    </div>
  </div>

  <div class="card">
    <div class="row g-0">
      <div class="col-md-4">
        <img src="/assets/imgs/research_pics/tss_1.png" class="img-fluid rounded-start" alt="transformation_certifcation">
        <img src="/assets/imgs/research_pics/tss_2.png" class="img-fluid rounded-start" alt="transformation_certifcation_methods">
      </div>
      <div class="col-md-8 research-div">
        <div class="card-body" style="min-height: 350px;">
          <h5 class="card-title">Transformation-specific Smoothing for Robustness Certification</h5>
          <p class="card-text">
            <p>
              <a href="https://arxiv.org/abs/2002.12398" target="_blank">[paper]</a>
              &nbsp;
              <a href="https://github.com/AI-secure/semantic-randomized-smoothing" target="_blank">[code]</a>
              &nbsp;
              <a href="/assets/research_slides/TSS-CCS21-slides.pdf" target="_blank">[slides]</a>
              &nbsp;
              <a href="https://dl.acm.org/doi/10.1145/3460120.3485258#supplementary-materials" target="_blank">[talk]</a>
            </p>
            <p>
              <ul>
                <li>The first scalable certification approach against natural transformations based on randomized smoothing, rigorous Lipschitz analysis, and stratified sampling.</li>
                <li>Achieving certified robustness against natural transformations such as rotation, scaling, brightness change, and Gaussian blurring that are common in the physical world. Prior to this work, robustness certification is limited to \(\ell_p\) bounded perturbations to our best knowledge.</li>
                <li>For the first time, we certify non-trivial robustness (>30% certified robust accuracy against any rotation attack within \(\pm 30^\circ\)) on the large-scale ImageNet dataset.</li>
                <li>Open source code ready for use.</li>
              </ul>
            </p>
          </p>
        </div>
        <div class="card-footer text-muted">
          ACM CCS 2021
        </div>
      </div>
    </div>
  </div>

<div class="row" style="margin-top: 50px;">
  <h3>Selected Awards</h3>
  <hr>
  <ul>
    <li>[2025] Our lab received <a href="https://www.nserc-crsng.gc.ca/Professors-Professeurs/Grants-Subs/DGIGP-PSIGP_eng.asp" target="_blank">NSERC Discovery Grant with Launch Supplement</a>.</li>
    <li>[2024] Linyi Li selected as <a href="https://aaai.org/conference/aaai/aaai-25/new-faculty-highlights-program/" target="_blank">AAAI 2025 New Faculty Highlights</a>.</li>
    <li>[2023] Winner of International Verification of Neural Networks Competition (<a href="https://arxiv.org/abs/2312.16760" target="_blank">VNN-COMP 2023</a>) where Dr. Linyi Li is the team co-leader.</li>
    <li>[2022] Linyi Li selected as <a href="https://datascience.uchicago.edu/research/postdoctoral-programs/rising-stars/2022/" target="_blank">Rising Stars in Data Science</a> at DSI, University of Chicago.</li>
    <li>[2022] Linyi Li received <a href="https://sites.google.com/view/advml/advml-rising-star-award" target="_blank">2022 AdvML Rising Star Award</a>.</li>
  </ul>
</div>



